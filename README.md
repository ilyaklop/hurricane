# hurricane
Application for making reports on hurricane data

## Общее описание функционала:
Проект предназначен для экспериментов над трансформацией и сохранением данных на примере датасета hurricane (atlantic.csv). Для промышленного использования необходимо подстроить параметры. 
1)create_cyclones_v4 - просто создаст таблицу в базе данных hurricane (которую необходимо заблаговременно создать). Таску автоматического заполнения из файла можно дорабатывать разными способами. В текущей реализации она не работает. 
2) create_reports_v1 - основной скрипт создания ежедневных отчетов. Для эффективности тестирования и расчетов за исторический период был использован параметр catchup=False. Скрипт создает отчеты только для дней, за которые есть данные, и сохраняет в каталог data.
3) create_history_v10 - создает историю из файлов и сохраняет в cyclones_hurricane. Работает последовательно для каждого файла за указанный промежуток времени catchup=False, max_active_runs=1. Каждый обработанный файл удаляет из каталога. (решение принято в пользу удобной настройки сенсора на текущую папку в случае, если понадобится обновить файл за последний день)  
4) check_updated_file_v2 - откатывает историю на 1 день назад, если обнаружен файл за последнюю обработанню дату, уже после удаления файла предыдущим дагом из каталога. 

## Описание запуска проекта:
1) склонировать репозиторий 
2) собрать докер образ 
docker build . --tag hurricane:latest
3) поднять контейнер со всем содержимым
docker-compose up -d
4) создать базу данных через любой инструмент управления (я использовал DBeaver)
hurricane
5) создать коннекшены через web-интерфейс airflow:
  a) коннекшн к базе схеме hurricane (conn_id =postgres_localhost, host = host.docker.internal, schema=hurricane, port=5432)
  б) коннекшн к внутреннему пути (если требуется) fs_conn_id = fs_default
6) запустить dag: create_cyclones_v4 (он просто создаст таблицу, адекватно использовать функцию COPY не решился из-за нежелания менять типы данных)
7) залить в созданную таблиу данные из файла в каталоге data (использовать имеено этот файл необходимо, т.к. в нем приведенные к норм виду имена полей таблицы) 
8) запусить dag: create_reports_v1 (он создает файлы с необходимым данными за каждый день. работает по месяцам) для запуска за исторический период:
airflow dags backfill -s 2013-10-01 -e 2013-10-31 create_reports_v1   (датами можно управлять. дату окончания желательно ставить на начало текущего месяца)

 --Примечание: для тестирования функции отката истории на 1(последний) день, рекомендуется на этом этапе копировать какие-нибудь файлы в другой каталог.
 
9) запустить dag: create_history_v10 (он создает историю из файлов и сохраняет в cyclones_hurricane. Рекомендуется для тестирования использовать небольшой промежуток времениБ, так как создание истории требует последовательного обращения к файлам. Запуск сразу за весь исторический период может выполнятся долго)
airflow dags backfill -s 2013-10-01 -e 2013-10-06 create_history_v10

Для тестирования функции обновления данных за последний обработанный день скопировать обратно сохраненные в другом каталоге файлы

10) запустить dag: check_updated_file_v2 ( в случае обнаружения в каталоге файла за текущую дату, откатит историю на 1 день назад)
airflow dags backfill -s 2013-10-06 -e 2013-10-06 check_updated_file_v2
после чего можно снова запустить dag: create_history_v10 за 1 день. Он запишет новую историю за указанный день. 
